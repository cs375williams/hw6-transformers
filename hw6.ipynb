{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc95f30",
   "metadata": {},
   "source": [
    "# Homework 6: Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bfca0",
   "metadata": {},
   "source": [
    "The goals of this assignment are:\n",
    "1. Develop a better understanding of the *self-attention mechanism* in Transformers by implementing it in numpy. \n",
    "2. Understand and train a BERT-based model a variant on *coreference resolution.* \n",
    "3. Strengthen your understanding of using HuggingFace's `transformers` package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05e52d",
   "metadata": {},
   "source": [
    "## Organization and Instructions\n",
    "Execute the code cells in Part 1 to understand the background for this assignment. You will not need to modify or add anything to Part 1. Part 2 is where your solution begins.\n",
    "\n",
    "**Part 1: Background.** \n",
    "- 1A. Environment set-up \n",
    "- 1B. Data exploration \n",
    "\n",
    "**Part 2: Your implementation.** \n",
    "- 2A. Self-attention \n",
    "- 2B. Zero-shot predictions \n",
    "- 2C. Fine-tuning \n",
    "\n",
    "\n",
    "**Addtional instructions.** \n",
    "- Please follow the 50-foot rule. Your submitted solution and code must be yours alone. Copying and pasting a solution from the internet or another source is considered a violation of the honor code. \n",
    "\n",
    "**Evaluation.** Your solution will be evaluated *manually* by the TAs and instructor. \n",
    "\n",
    "To help bridge the gap between previous homeworks and the final project. We are **not giving you an autograder**. We hope to help wean you off the grader and give you practice testing your own code.\n",
    "\n",
    "Please come see us during help hours if you need additional assistance! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f28832",
   "metadata": {},
   "source": [
    "## 1A. Environment Set-up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c8ca2",
   "metadata": {},
   "source": [
    "If you set-up your conda environment correctly in HW0, you should see `Python [conda env:cs375]` as the kernel in the upper right-hand corner of the Jupyter webpage you are currently on. Run the cell below to make sure your environment is correctly installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c48f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check \n",
    "# Return to HW0 if you run into errors in this cell \n",
    "# Do not modify this cell \n",
    "import os\n",
    "assert os.environ['CONDA_DEFAULT_ENV'] == \"cs375\"\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3 and sys.version_info.minor == 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77f509",
   "metadata": {},
   "source": [
    "If there are any errors after running the cell above, return to the instructions from `HW0`. If you are still having difficulty, reach out to the instructor or TAs via Piazza. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d637bf",
   "metadata": {},
   "source": [
    "#### Installing other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41206a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import typing\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0bc86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util #inspect util.py to see what is in this file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee52cb",
   "metadata": {},
   "source": [
    "## 1B. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730abba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8610ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsc_data = load_dataset(\"coref-data/davis_wsc_raw\", \"wsc273\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa97fa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'pronoun', 'pronoun_loc', 'quote', 'quote_loc', 'options', 'label', 'source'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10137162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The trophy doesn't fit into the brown suitcase because it is too large.\",\n",
       " 'pronoun': 'it',\n",
       " 'pronoun_loc': 55,\n",
       " 'quote': 'it is too large',\n",
       " 'quote_loc': 55,\n",
       " 'options': ['the trophy', 'the suitcase'],\n",
       " 'label': 0,\n",
       " 'source': 'Hector Levesque'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsc_data['test'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078bcebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The trophy doesn't fit into the brown suitcase because it is too small.\",\n",
       " 'pronoun': 'it',\n",
       " 'pronoun_loc': 55,\n",
       " 'quote': 'it is too small',\n",
       " 'quote_loc': 55,\n",
       " 'options': ['the trophy', 'the suitcase'],\n",
       " 'label': 1,\n",
       " 'source': 'Hector Levesque'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsc_data['test'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430ccd4",
   "metadata": {},
   "source": [
    "In this homework, we will use the WinoGrande dataset. You can read more about the dataset in [this paper](https://cdn.aaai.org/ojs/6399/6399-13-9624-1-10-20200517.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de9f3a",
   "metadata": {},
   "source": [
    "Here is Table 1 from the WinoGrande paper with examples:  \n",
    "\n",
    "![](figs/winograd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d855501",
   "metadata": {},
   "source": [
    "HuggingFace provides a Python package for loading (and uploading datasets). You can read more about the `datasets` Python package [here](https://huggingface.co/docs/datasets/en/index). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beccf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825a7bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. train exs= 640\n",
      "Num. dev exs= 500\n"
     ]
    }
   ],
   "source": [
    "# Load the WinoGrande dataset\n",
    "dataset = load_dataset(\"allenai/winogrande\", \"winogrande_s\", trust_remote_code=True)\n",
    "\n",
    "# Access the training and validation splits\n",
    "train_dataset = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"].select(range(500)) #We'll just look at 200 dev exs\n",
    "\n",
    "print(f\"Num. train exs= {len(train_dataset)}\")\n",
    "print(f\"Num. dev exs= {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de732df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'I had to read an entire story for class tomorrow. Luckily, the _ was short.', 'option1': 'story', 'option2': 'class', 'answer': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at one example from the validation dataset\n",
    "print(validation_dataset[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0a59e",
   "metadata": {},
   "source": [
    "Above, the `'sentence'` is the full sentence with a `_` for where the pronoun or noun options should go. \n",
    "\n",
    "Then `option1` and `option2` are the two token spans from the sentence the model will eventually choose from and `answer` is the correct answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07013b71",
   "metadata": {},
   "source": [
    "## 2A. Self-attention\n",
    "\n",
    "In this part, you will implement the parallelized version of the *masked* self-attention mechanism in Transformers using only numpy.\n",
    "\n",
    "\n",
    "Recall, for each layer $k$ in the transformer block we have "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58916e6f",
   "metadata": {},
   "source": [
    "For a single example with $n$ tokens and embedding dimension $d$, we first have $X^k$, the contextual embedding matrix (size $n\\times d$) for layer $k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a4705",
   "metadata": {},
   "source": [
    "Then, we introduce the weights, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d6663",
   "metadata": {},
   "source": [
    "$$ Q = X^k \\times W_Q$$ \n",
    "$$ K = X^k \\times W_K$$\n",
    "$$ V = X^k \\times W_V $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b965e22",
   "metadata": {},
   "source": [
    "and use the new matrices to get the contextual embedding matrix for the next layer, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6c218",
   "metadata": {},
   "source": [
    "$$ X^{k+1} = \\text{softmax} \\bigg( \\text{mask} \\bigg( \\frac{QK^T}{\\sqrt{d}} \\bigg) \\bigg) V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3600819",
   "metadata": {},
   "source": [
    "This is computationally efficient in a matrix-multiplication-optimized library like `numpy` because it should have **no for-loops!** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601540b0",
   "metadata": {},
   "source": [
    "Let's implement self-attention for the (modified) example we were looking at in Part 1 \n",
    "\n",
    "*\"I had to read an entire story for class tomorrow. Luckily, it was short.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e41436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens for our example \n",
    "toks = [\"i\", \"had\", \"to\", \"read\", \"an\", \n",
    "        \"entire\", \"story\", \"for\", \"class\", \"tomorrow\", \".\",\n",
    "       \"luckily\", \"it\", \"was\", \"short\", \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba4bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-specified embeddings and weights (for testing)\n",
    "X, W_Q, W_K, W_V = util.load_attention_data(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8fb6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your approach in this function\n",
    "\n",
    "def self_attention(X: np.ndarray, W_Q: np.ndarray, \n",
    "                   W_K: np.ndarray, W_V: np.ndarray) -> np.ndarray: \n",
    "    \"\"\"\n",
    "    Implements (masked) self-attention mechanism for a single layer \n",
    "    (and a single example)\n",
    "    \n",
    "    Returns: X_new, a np.ndarray that is the same shape as X\n",
    "    \n",
    "    Notes:\n",
    "    - You can only use numpy for this part of the homework and no other packages\n",
    "    - Your solution must not have any for-loops!\n",
    "    \n",
    "    Tips: \n",
    "        - Double-check the shapes of all the matrices you're working with. \n",
    "        - We recommend making a helper function for the softmax.\n",
    "        - You may a subset of these numpy methods and operators helpful: `np.exp`, `@`, `np.triu_indicies`, `np.reshape`, `np.inf`, `np.broadcast_to`, `np.choose`.  \n",
    "    \"\"\"\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d36bd",
   "metadata": {},
   "source": [
    "## 2B. Zero-shot predictions\n",
    "\n",
    "Now, we will use a distilled version of \"RoBERTa\" (a BERT variant) to make zero-shot predictions on the WinoGrande dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d696c",
   "metadata": {},
   "source": [
    "#### Tokenization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac9c4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f34eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4752d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The city councilmen refused the demonstrators a permit because they feared violence.',\n",
       " 'pronoun': 'they',\n",
       " 'pronoun_loc': 63,\n",
       " 'quote': 'they feared violence',\n",
       " 'quote_loc': 63,\n",
       " 'options': ['The city councilmen', 'The demonstrators'],\n",
       " 'label': 0,\n",
       " 'source': '(Winograd 1972)'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsc_data['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e1844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The city councilmen refused the demonstrators a permit because they feared violence.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First example in the dev dataset (see dataset loading in Part 1B above)\n",
    "text1 = wsc_data['test'][0]['text']\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93c1159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.find(\"the demonstrators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2add8122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sarah was a much better surgeon than Maria so _ always got the easier cases.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = validation_dataset[0]['sentence']\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe9c484b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 4532, 2001, 1037, 2172, 2488, 9431, 2084, 3814, 2061, 1035, 2467,\n",
       "         2288, 1996, 6082, 3572, 1012,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'offset_mapping': tensor([[[ 0,  0],\n",
       "         [ 0,  5],\n",
       "         [ 6,  9],\n",
       "         [10, 11],\n",
       "         [12, 16],\n",
       "         [17, 23],\n",
       "         [24, 31],\n",
       "         [32, 36],\n",
       "         [37, 42],\n",
       "         [43, 45],\n",
       "         [46, 47],\n",
       "         [48, 54],\n",
       "         [55, 58],\n",
       "         [59, 62],\n",
       "         [63, 69],\n",
       "         [70, 75],\n",
       "         [75, 76],\n",
       "         [ 0,  0]]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts to tokens and attention mask \n",
    "# The attention mask will be 0 if there are special \"PAD\" tokens\n",
    "inputs = tokenizer(text1, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5daad8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'sarah',\n",
       " 'was',\n",
       " 'a',\n",
       " 'much',\n",
       " 'better',\n",
       " 'surgeon',\n",
       " 'than',\n",
       " 'maria',\n",
       " 'so',\n",
       " '_',\n",
       " 'always',\n",
       " 'got',\n",
       " 'the',\n",
       " 'easier',\n",
       " 'cases',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bbcaf",
   "metadata": {},
   "source": [
    "Note: Above, when we see the `###` characters before tokens, this means the BERT tokenizer has split a word into subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e6ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the function below \n",
    "def which_tok_index(tok_string: str, sentence: str, inputs: torch.tensor) -> int:\n",
    "    \"\"\"\n",
    "    Inputs: the token string (tok_string) of interest, the original sentence\n",
    "    and the tokenized input tensors \n",
    "    \n",
    "    Returns: (int) the first index that matches the tok_string. \n",
    "    \n",
    "        If tok_string gets tokenized into multiple tokens, return the *first* index corresponding\n",
    "        to the multi-token span. \n",
    "\n",
    "        If there is no match (which could happen), return 0. \n",
    "    \n",
    "    Example: \n",
    "        tok_string=\"sarah\"\n",
    "        \n",
    "        input_ids = {'input_ids': tensor([[ 101, 4532, 2001, 1037, 2172, 2488, 9431, 2084, 3814, 2061, 1035, 2467,\n",
    "         2288, 1996, 6082, 3572, 1012,  102]]), \n",
    "                     'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), \n",
    "                     'offset_mapping': tensor([[[ 0,  0],\n",
    "                     [ 0,  5],\n",
    "                     [ 6,  9],\n",
    "                     [10, 11],\n",
    "                     [12, 16],\n",
    "                     [17, 23],\n",
    "                     [24, 31],\n",
    "                     [32, 36],\n",
    "                     [37, 42],\n",
    "                     [43, 45],\n",
    "                     [46, 47],\n",
    "                     [48, 54],\n",
    "                     [55, 58],\n",
    "                     [59, 62],\n",
    "                     [63, 69],\n",
    "                     [70, 75],\n",
    "                     [75, 76],\n",
    "                     [ 0,  0]]])}\n",
    "        \n",
    "        Returns: 1 \n",
    "        \n",
    "        This example returns 1 since the token id at index 1 (value 432)\n",
    "        starts at character index 6 in the orginal sentence and corresponds to \"sarah.\"\n",
    "        \n",
    "    Tips:  \n",
    "        - Understaning 'offset_mapping' and Python string methods may be helpful here\n",
    "        - tokenizer.convert_ids_to_tokens could help with debugging \n",
    "    \"\"\"\n",
    "    # find the start character\n",
    "    start_indx_goal = sentence.find(tok_string)\n",
    "    \n",
    "    for i, tok in enumerate(inputs['offset_mapping'][0]):\n",
    "        start, end = tok\n",
    "        start = start.item()\n",
    "        end = end.item()\n",
    "        if end == 0: continue \n",
    "        #see if we find a match \n",
    "        if start_indx_goal == start: return i \n",
    "    \n",
    "    return 0 # delete and replace with your code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dca1f6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 == 1?\n",
      "8 == 8?\n",
      "10 == 10?\n"
     ]
    }
   ],
   "source": [
    "# Unit test\n",
    "sent = validation_dataset[0]['sentence']\n",
    "inputs = tokenizer(sent, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "\n",
    "t1 = which_tok_index(\"sarah\", sent.lower(), inputs)\n",
    "print(t1, \"== 1?\")\n",
    "t2 = which_tok_index(\"maria\", sent.lower(), inputs)\n",
    "print(t2, \"== 8?\")\n",
    "t3 = which_tok_index(\"_\", sent.lower(), inputs)\n",
    "print(t3, \"== 10?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d4acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 == 7?\n",
      "12 == 12?\n",
      "0 == 0?\n"
     ]
    }
   ],
   "source": [
    "# Another unit test \n",
    "sent3 = validation_dataset[3]['sentence']\n",
    "inputs3 = tokenizer(sent3, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "\n",
    "t1 = which_tok_index(validation_dataset[3]['option1'].lower(), sent3, inputs3)\n",
    "print(t1, \"== 7?\")\n",
    "t2 = which_tok_index(validation_dataset[3]['option2'].lower(), sent3, inputs3)\n",
    "print(t2, \"== 12?\")\n",
    "t3 = which_tok_index(\"blah\", sent3, inputs3)\n",
    "print(t3, \"== 0?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02109352",
   "metadata": {},
   "source": [
    "#### Zero-shot prediction\n",
    "\n",
    "Now, we'll use the model to make zero-shot predictions. Note, this is \"zero-shot\" because we haven't ever trained the model on this particular task or dataset.  \n",
    "\n",
    "Here's how we will make zero-shot predictions: \n",
    "1. Pass the sentence (after tokenization) into the pre-trained model \n",
    "2. Obtain the final layer contextual embeddings for the `\"_\"` token as well as the *first* token for the substring of `option1` and likewise for `option2`. \n",
    "3. Find the cosine similarity between these contextual embeddings between `\"_\"` and the embedding we chose for `option1` and likewise for `option2`. \n",
    "4. Whichever has the higher cosine similarity (`option1` or `option2`), make this the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73528eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your implementation\n",
    "def zero_shot_predictions(model, tokenizer, dataset) -> List[int]: \n",
    "    \"\"\"\n",
    "    Make zero-shot predictions with the last layer contextual embedding\n",
    "    cosine similarity method described in the previous cell. \n",
    "    \n",
    "    Returns: \n",
    "        List[str], a list of strings, one element for each \n",
    "        example in the input dataset. Each element is an int: \n",
    "            - 1 corresponding to \"option1\" in the dataset\n",
    "            - 2 corresponding to \"option2\" in the dataset\n",
    "    \n",
    "    Note: \n",
    "        - For now, it's ok if you have a for-loop over examples. \n",
    "          (In an actual industry setting, you would make this all parallelized)\n",
    "        - You might make use of the `which_tok_index()` helper function \n",
    "        you just implemented \n",
    "        - The documentation on AutoModelForSequenceClassification may be helpful here. \n",
    "        - torch.nn.functional may have some helpful methods \n",
    "        - Using model.eval() and torch.no_grad() will speed things up (since Pytorch will not\n",
    "            have to make the computation graph)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        # Get the contextual embeddings (last hidden states)\n",
    "        text = dataset[i]['sentence']\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        last_hidden_states = outputs.hidden_states[-1][0]\n",
    "\n",
    "        #Now get the embedding for \"_\"\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "        underscore_indx = which_tok_index(\"_\", text.lower(), inputs)\n",
    "        underscore_embed = last_hidden_states[underscore_indx]\n",
    "\n",
    "        # Embedding for option1\n",
    "        option1 = dataset[i]['option1'].lower()\n",
    "        option1_idx =  which_tok_index(option1, text.lower(), inputs)\n",
    "        option1_embed = last_hidden_states[option1_idx]\n",
    "\n",
    "        #Embedding for option2\n",
    "        option2 = dataset[i]['option2'].lower()\n",
    "        option2_idx =  which_tok_index(option2, text.lower(), inputs)\n",
    "        option2_embed = last_hidden_states[option2_idx]\n",
    "        \n",
    "        #print(i, \"indexes=\", underscore_indx, option1_idx, option2_idx)\n",
    "\n",
    "        #Now cosine sims \n",
    "        #print(option1, option2)\n",
    "        cos_sim1 = F.cosine_similarity(underscore_embed, option1_embed, dim=0)\n",
    "        cos_sim2 = F.cosine_similarity(underscore_embed, option2_embed, dim=0)\n",
    "\n",
    "        #Predictions\n",
    "        try: \n",
    "            if cos_sim1 > cos_sim2: \n",
    "                preds.append(1)\n",
    "            else: \n",
    "                preds.append(2)\n",
    "        except: \n",
    "            print(i, cos_sim1, cos_sim2)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ced1ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert/distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# You might see a warning below. \n",
    "# We'll end up doing this in the next part of the homework;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa4ccdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code on just a single example \n",
    "zero_shot_predictions(model, tokenizer, validation_dataset.select(range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97d45887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make the full predictions \n",
    "preds = zero_shot_predictions(model, tokenizer, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "922bac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and check the following\n",
    "#len(preds) == len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c02e9e2",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3daaf618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of baseline (maj. class)= 0.67\n",
      "F1 of zero-shot= 0.5\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    truth = [int(x['answer']) for x in validation_dataset]\n",
    "    assert len(truth) == len(preds)\n",
    "    y_true = np.array(truth)\n",
    "    y_pred = np.array(preds)\n",
    "    y_baseline = np.ones(len(y_true)) *2\n",
    "    print(\"F1 of baseline (maj. class)=\", np.round(f1_score(y_true, y_baseline, pos_label=2), 2))\n",
    "    print(\"F1 of zero-shot=\", np.round(f1_score(y_true, y_pred, pos_label=2), 2))\n",
    "except: \n",
    "    print(\"Need len(truth) == len(preds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45446669",
   "metadata": {},
   "source": [
    "How does your zero-shot model compare to the baseline? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5009bbae",
   "metadata": {},
   "source": [
    "##  2C. Fine-tuning\n",
    "\n",
    "Now we'll fine-tune our model on the training dataset. We'll give you some code to help with the pre-processing. It's your job to use `TrainingArguments` and `Trainer` from HuggingFace in order to train the model. \n",
    "\n",
    "Tips: \n",
    "- [This](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) HuggingFace tutorial may be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1d9df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name =  \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04e5a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KATIE TODO: replace the \"_\"! Duh! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_winograde_data(dataset):\n",
    "    \"\"\"\n",
    "    In this preprocessing function for classification, we create two training \n",
    "    examples per original example by substituting option1 or option2 for _. \n",
    "    \n",
    "    For instance, with the example \n",
    "        {'sentence': 'I had to read an entire story for class tomorrow. \n",
    "                        Luckily, the _ was short.', \n",
    "        'option1': 'story', 'option2': 'class', 'answer': '1'}\n",
    "        \n",
    "    We create \n",
    "        x1 = \"I had to read an entire story for class tomorrow. Luckily, the story was short.\"\n",
    "        y1= 1 (correct)\n",
    "        \n",
    "        x2 = \"I had to read an entire story for class tomorrow. Luckily, the class was short.\"\n",
    "        y2 = 0 (incorrect)\n",
    "    \"\"\"\n",
    "    \n",
    "    out = []\n",
    "    for i, x in enumerate(dataset):\n",
    "        new_x = {}\n",
    "        # Create a \"positive answer\"\n",
    "        if x['answer'] == '1': \n",
    "            replace_str = x['option1']\n",
    "        else: \n",
    "            replace_str = x['option2']\n",
    "        new_x['text'] = x['sentence'].replace(\"_\", replace_str)\n",
    "        new_x['label'] = 1 # y=1\n",
    "        out.append(new_x)\n",
    "\n",
    "        #Then a \"negative answer\"\n",
    "        if x['answer'] == '1': \n",
    "            replace_str = x['option2'] # Opposite!!! \n",
    "        else: \n",
    "            replace_str = x['option1']\n",
    "        new_x['text'] = x['sentence'].replace(\"_\", replace_str)\n",
    "        new_x['label'] = 0 # y=0\n",
    "        out.append(new_x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97ca479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1280\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_for_classification = Dataset.from_list(substitute_winograde_data(train_dataset))\n",
    "train_for_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7853ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_for_classification = Dataset.from_list(substitute_winograde_data(validation_dataset))\n",
    "dev_for_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "027ed1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], truncation=True, padding=\"max_length\", max_length=100)\n",
    "\n",
    "# def add_labels(example, idx):\n",
    "#     example['label'] = int(example['answer'])-1\n",
    "#     return example\n",
    "\n",
    "# encoded_train = train_dataset.map(preprocess_function, batched=True)\n",
    "# encoded_train = encoded_train.map(add_labels, with_indices=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33ff5535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253a1c595f654f70bbc095863e59d040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train = train_for_classification.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb382edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1280\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3de0f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f064b750164ea2916776c558ffc878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dev = dev_for_classification.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31936dc6",
   "metadata": {},
   "source": [
    "TODO: It's your job to use `TrainingArguments` and `Trainer` from HuggingFace in order to train `model_tune` above! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb979bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f875f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "f1_score_func = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b7f155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return f1_score_func.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68c2288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"saved\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False, # NO HUB NEEDED! \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "067d28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train,\n",
    "    eval_dataset=encoded_dev,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce7f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17/160 01:30 < 14:27, 0.16 it/s, Epoch 0.20/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198a8b1",
   "metadata": {},
   "source": [
    "Be sure to report your final F1 score on the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4366e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: put your eval code here ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a45ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output = trainer.predict(encoded_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = predictions_output.metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab58fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function2(dataset):\n",
    "    return tokenizer(dataset[\"text\"], truncation=True, padding=\"max_length\", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the WSC data \n",
    "wsc_encode = wsc_data.map(preprocess_function2, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output = trainer.predict(wsc_encode['test'])\n",
    "metrics = predictions_output.metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f93ec2",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [[ ! -f \"./hw6.ipynb\" ]]\n",
    "then\n",
    "    echo \"WARNING: Did not find notebook in Jupyter working directory. Manual solution: go to File->Download .ipynb to download your notebok and other files, then zip them locally.\"\n",
    "else\n",
    "    echo \"Found notebook file, creating submission zip...\"\n",
    "    zip -r submission.zip hw6.ipynb\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
