{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc95f30",
   "metadata": {},
   "source": [
    "# Homework 6: Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bfca0",
   "metadata": {},
   "source": [
    "The goals of this assignment are:\n",
    "1. Develop a better understanding of the *self-attention mechanism* in Transformers by implementing it in numpy. \n",
    "2. Understand and train a BERT-based model a variant on *coreference resolution.* \n",
    "3. Strengthen your understanding of using HuggingFace's `transformers` package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05e52d",
   "metadata": {},
   "source": [
    "## Organization and Instructions\n",
    "Execute the code cells in Part 1 to understand the background for this assignment. You will not need to modify or add anything to Part 1. Part 2 is where your solution begins.\n",
    "\n",
    "**Part 1: Background.** \n",
    "- 1A. Environment set-up \n",
    "- 1B. Data exploration \n",
    "\n",
    "**Part 2: Your implementation.** \n",
    "- 2A. Self-attention \n",
    "- 2B. Zero-shot predictions \n",
    "- 2C. Fine-tuning \n",
    "\n",
    "\n",
    "**Addtional instructions.** \n",
    "- Please follow the 50-foot rule. Your submitted solution and code must be yours alone. Copying and pasting a solution from the internet or another source is considered a violation of the honor code. \n",
    "\n",
    "**Evaluation.** Your solution will be evaluated *manually* by the TAs and instructor. \n",
    "\n",
    "To help bridge the gap between previous homeworks and the final project. We are **not giving you an autograder**. We hope to help wean you off the grader and give you practice testing your own code.\n",
    "\n",
    "Please come see us during help hours if you need additional assistance! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f28832",
   "metadata": {},
   "source": [
    "## 1A. Environment Set-up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c8ca2",
   "metadata": {},
   "source": [
    "If you set-up your conda environment correctly in HW0, you should see `Python [conda env:cs375]` as the kernel in the upper right-hand corner of the Jupyter webpage you are currently on. Run the cell below to make sure your environment is correctly installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c48f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check \n",
    "# Return to HW0 if you run into errors in this cell \n",
    "# Do not modify this cell \n",
    "import os\n",
    "assert os.environ['CONDA_DEFAULT_ENV'] == \"cs375\"\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3 and sys.version_info.minor == 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77f509",
   "metadata": {},
   "source": [
    "If there are any errors after running the cell above, return to the instructions from `HW0`. If you are still having difficulty, reach out to the instructor or TAs via Piazza. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d637bf",
   "metadata": {},
   "source": [
    "#### Installing other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41206a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import typing\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util #inspect util.py to see what is in this file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee52cb",
   "metadata": {},
   "source": [
    "## 1B. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430ccd4",
   "metadata": {},
   "source": [
    "In this homework, we will use the WinoGrande dataset. You can read more about the dataset in [this paper](https://cdn.aaai.org/ojs/6399/6399-13-9624-1-10-20200517.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de9f3a",
   "metadata": {},
   "source": [
    "Here is Table 1 from the WinoGrande paper with examples:  \n",
    "\n",
    "![](figs/winograd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d855501",
   "metadata": {},
   "source": [
    "HuggingFace provides a Python package for loading (and uploading datasets). You can read more about the `datasets` Python package [here](https://huggingface.co/docs/datasets/en/index). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WinoGrande dataset\n",
    "dataset = load_dataset(\"allenai/winogrande\", \"winogrande_s\", trust_remote_code=True)\n",
    "\n",
    "# Access the training and validation splits\n",
    "train_dataset = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"].select(range(100)) #We'll just look at 100 dev exs\n",
    "\n",
    "print(f\"Num. train exs= {len(train_dataset)}\")\n",
    "print(f\"Num. dev exs= {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de732df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one example from the validation dataset\n",
    "print(validation_dataset[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0a59e",
   "metadata": {},
   "source": [
    "Above, the `'sentence'` is the full sentence with a `_` for where the pronoun or noun options should go. \n",
    "\n",
    "Then `option1` and `option2` are the two token spans from the sentence the model will eventually choose from and `answer` is the correct answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07013b71",
   "metadata": {},
   "source": [
    "## 2A. Self-attention\n",
    "\n",
    "In this part, you will implement the parallelized version of the *masked* self-attention mechanism in Transformers using only numpy.\n",
    "\n",
    "\n",
    "Recall, for each layer $k$ in the transformer block we have "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58916e6f",
   "metadata": {},
   "source": [
    "For a single example with $n$ tokens and embedding dimension $d$, we first have $X^k$, the contextual embedding matrix (size $n\\times d$) for layer $k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a4705",
   "metadata": {},
   "source": [
    "Then, we introduce the weights, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d6663",
   "metadata": {},
   "source": [
    "$$ Q = X^k \\times W_Q$$ \n",
    "$$ K = X^k \\times W_K$$\n",
    "$$ V = X^k \\times W_V $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b965e22",
   "metadata": {},
   "source": [
    "and use the new matrices to get the contextual embedding matrix for the next layer, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6c218",
   "metadata": {},
   "source": [
    "$$ X^{k+1} = \\text{softmax} \\bigg( \\text{mask} \\bigg( \\frac{QK^T}{\\sqrt{d}} \\bigg) \\bigg) V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3600819",
   "metadata": {},
   "source": [
    "This is computationally efficient in a matrix-multiplication-optimized library like `numpy` because it should have **no for-loops!** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601540b0",
   "metadata": {},
   "source": [
    "Let's implement self-attention for the (modified) example we were looking at in Part 1 \n",
    "\n",
    "*\"I had to read an entire story for class tomorrow. Luckily, it was short.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e41436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens for our example \n",
    "toks = [\"i\", \"had\", \"to\", \"read\", \"an\", \n",
    "        \"entire\", \"story\", \"for\", \"class\", \"tomorrow\", \".\",\n",
    "       \"luckily\", \"it\", \"was\", \"short\", \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-specified embeddings and weights (for testing)\n",
    "X, W_Q, W_K, W_V = util.load_attention_data(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your approach in this function\n",
    "\n",
    "def self_attention(X: np.ndarray, W_Q: np.ndarray, \n",
    "                   W_K: np.ndarray, W_V: np.ndarray) -> np.ndarray: \n",
    "    \"\"\"\n",
    "    Implements (masked) self-attention mechanism for a single layer \n",
    "    (and a single example)\n",
    "    \n",
    "    Returns: X_new, a np.ndarray that is the same shape as X\n",
    "    \n",
    "    Notes:\n",
    "    - You can only use numpy for this part of the homework and no other packages\n",
    "    - Your solution must not have any for-loops!\n",
    "    \n",
    "    Tips: \n",
    "        - Double-check the shapes of all the matrices you're working with. \n",
    "        - We recommend making a helper function for the softmax.\n",
    "        - You may a subset of these numpy methods and operators helpful: `np.exp`, `@`, `np.triu_indicies`, `np.reshape`, `np.inf`, `np.broadcast_to`, `np.choose`.  \n",
    "    \"\"\"\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d36bd",
   "metadata": {},
   "source": [
    "## 2B. Zero-shot predictions\n",
    "\n",
    "Now, we will use a distilled version of \"RoBERTa\" (a BERT variant) to make zero-shot predictions on the WinoGrande dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d696c",
   "metadata": {},
   "source": [
    "#### Tokenization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilroberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f34eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First example in the dev dataset (see dataset loading in Part 1B above)\n",
    "text1 = validation_dataset[0]['sentence']\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts to tokens and attention mask \n",
    "# The attention mask will be 0 if there are special \"PAD\" tokens\n",
    "inputs = tokenizer(text1, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5daad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bbcaf",
   "metadata": {},
   "source": [
    "Note: Above, when we see the `Ġ` character before tokens, this is how the RoBERTa tokenizer indicates spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the function below \n",
    "def which_tok_index(tok_string: str, input_ids: torch.tensor, tokenizer) -> int:\n",
    "    \"\"\"\n",
    "    Given the token string (tok_string) of interest, and the tokenizer, \n",
    "    return the first token index that matches the *beginning* of tok_string. \n",
    "    \n",
    "    If there is no match (which could happen), return 0. \n",
    "    \n",
    "    Example: \n",
    "        tok_string=\"Sarah\"\n",
    "        input_ids = tensor([0, 33671, 21, 10, 203, 357, 16308, 87,  \n",
    "        5011, 98, 18134, 460, 300, 5, 3013, 1200,  4, 2])\n",
    "        \n",
    "        Returns: 1 \n",
    "        \n",
    "        This example returns 1 since 33671 is the first index in 'input_ids' \n",
    "        and 33671 is also the token id \"Sarah\"\n",
    "        \n",
    "        The original sentence in this example was \n",
    "        sentence = \"Sarah was a much better surgeon than Maria so _ always got the easier cases.\"\n",
    "        \n",
    "    Notes:  \n",
    "        - Be sure to deal with the \"Ġ\"\n",
    "    \"\"\"\n",
    "    return 0 # delete and replace with your code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test\n",
    "inputs = tokenizer(validation_dataset[0]['sentence'], return_tensors=\"pt\")\n",
    "input_ids = inputs['input_ids'][0]\n",
    "t1 = which_tok_index(\"Sarah\", input_ids, tokenizer)\n",
    "print(t1, \"== 1?\")\n",
    "t2 = which_tok_index(\"Maria\", input_ids, tokenizer)\n",
    "print(t2, \"== 8?\")\n",
    "t3 = which_tok_index(\"_\", input_ids, tokenizer)\n",
    "print(t3, \"== 10?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another unit test \n",
    "inputs = tokenizer(validation_dataset[3]['sentence'], return_tensors=\"pt\")\n",
    "input_ids = inputs['input_ids'][0]\n",
    "t1 = which_tok_index(validation_dataset[3]['option1'], input_ids, tokenizer)\n",
    "print(t1, \"== 6?\")\n",
    "t2 = which_tok_index(\"blah\", input_ids, tokenizer)\n",
    "print(t2, \"== 0?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02109352",
   "metadata": {},
   "source": [
    "#### Zero-shot prediction\n",
    "\n",
    "Now, we'll use the model to make zero-shot predictions. Note, this is \"zero-shot\" because we haven't ever trained the model on this particular task or dataset.  \n",
    "\n",
    "Here's how we will make zero-shot predictions: \n",
    "1. Pass the sentence (after tokenization) into the pre-trained model \n",
    "2. Obtain the final layer contextual embeddings for the `\"_\"` token as well as the (first) token representing `option1` and `option2`. \n",
    "3. Find the cosine similarity between these contextual embeddings between `\"_\"` and the embedding we chose for `option1` as well as the cosine similarity between `\"_\"` and the embedding we chose for `option2`. \n",
    "4. Choose whichever pair has the higher cosine similarity as the prediction. \n",
    "\n",
    "Note: We have some precision-recall tradeoffs as well as potential errors in this zero-shot approach as since some strings for `option1` and `option2` will be represented by *multiple* tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73528eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your implementation\n",
    "def zero_shot_predictions(model, tokenizer, dataset) -> List[int]: \n",
    "    \"\"\"\n",
    "    Make zero-shot predictions with the last layer contextual embedding\n",
    "    cosine similarity method described in the previous cell. \n",
    "    \n",
    "    Returns: \n",
    "        List[str], a list of strings, one element for each \n",
    "        example in the input dataset. Each element is an int: \n",
    "            - 1 corresponding to \"option1\" in the dataset\n",
    "            - 2 corresponding to \"option2\" in the dataset\n",
    "    \n",
    "    Note: \n",
    "        - For now, it's ok if you have a for-loop over examples. \n",
    "          (In an actual industry setting, you would make this all parallelized)\n",
    "        - You might make use of the `which_tok_index()` helper function \n",
    "        you just implemented \n",
    "        - The documentation on AutoModelForTokenClassification may be helpful here. \n",
    "        - torch.nn.functional may have some helpful methods \n",
    "        - Using model.eval() and torch.no_grad() will speed things up (since Pytorch will not\n",
    "        have to make the computation graph)\n",
    "    \"\"\"\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# You might see a warning below. \n",
    "# We'll end up doing this in the next part of the homework;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ccdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code on just a single example \n",
    "zero_shot_predictions(model, tokenizer, validation_dataset.select(range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d45887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the full predictions \n",
    "preds = zero_shot_predictions(model, tokenizer, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: Is the following true for your dataset? \n",
    "# len(preds) == len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c02e9e2",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daaf618",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    assert len(truth) == len(preds)\n",
    "    truth = [int(x['answer']) for x in validation_dataset]\n",
    "    y_true = np.array(truth)\n",
    "    y_pred = np.array(preds)\n",
    "    y_baseline = np.ones(len(y_true)) *2\n",
    "    print(\"F1 of baseline (maj. class)=\", np.round(f1_score(y_true, y_baseline, pos_label=2), 2))\n",
    "    print(\"F1 of zero-shot=\", np.round(f1_score(y_true, y_pred, pos_label=2), 2))\n",
    "except: \n",
    "    print(\"Need preds to be equal to truth for eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45446669",
   "metadata": {},
   "source": [
    "How does your zero-shot model compare to the baseline? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5009bbae",
   "metadata": {},
   "source": [
    "##  2C. Fine-tuning\n",
    "\n",
    "Now we'll fine-tune our model on the training dataset. We'll give you some code to help with the pre-processing. It's your job to use `TrainingArguments` and `Trainer` from HuggingFace in order to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilroberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
    "model_tune = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ed1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    return tokenizer(dataset[\"sentence\"], truncation=True, padding=\"max_length\", max_length=100)\n",
    "\n",
    "def add_labels(example, idx):\n",
    "    example['label'] = int(example['answer'])-1\n",
    "    return example\n",
    "\n",
    "encoded_train = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_train = encoded_train.map(add_labels, with_indices=True)\n",
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check that the following two cells match \n",
    "encoded_train['answer'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train['label'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dev = validation_dataset.map(preprocess_function, batched=True)\n",
    "encoded_dev = encoded_dev.map(add_labels, with_indices=True)\n",
    "encoded_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31936dc6",
   "metadata": {},
   "source": [
    "TODO: It's your job to use `TrainingArguments` and `Trainer` from HuggingFace in order to train `model_tune` above! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb979bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: put your training code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198a8b1",
   "metadata": {},
   "source": [
    "Be sure to report your final F1 score on the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d72acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: put your validation code here ### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f93ec2",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [[ ! -f \"./hw6.ipynb\" ]]\n",
    "then\n",
    "    echo \"WARNING: Did not find notebook in Jupyter working directory. Manual solution: go to File->Download .ipynb to download your notebok and other files, then zip them locally.\"\n",
    "else\n",
    "    echo \"Found notebook file, creating submission zip...\"\n",
    "    zip -r submission.zip hw6.ipynb\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
